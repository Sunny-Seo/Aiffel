{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c424be35",
   "metadata": {},
   "source": [
    "# 4. 작사가 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7485ea7",
   "metadata": {},
   "source": [
    "### 학습과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a06c241",
   "metadata": {},
   "source": [
    "1. 데이터 다운로드\n",
    "2. 데이터 읽어오기\n",
    "3. 데이터 정제\n",
    "4. 평가 데이터셋 분리\n",
    "5. 인공지능 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a41348b",
   "metadata": {},
   "source": [
    "### 데이터 읽어오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0bc3e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터의 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list=  glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "#여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()  # 텍스트를 라인 단위로 끊어서 읽어오기\n",
    "        raw_corpus.extend(raw)\n",
    "        \n",
    "print('데이터의 크기:', len(raw_corpus))\n",
    "print('Examples:\\n', raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3bd579",
   "metadata": {},
   "source": [
    "### 데이터 정제하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "797f33ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now I've heard there was a secret chord\n",
      "That David played, and it pleased the Lord\n",
      "But you don't really care for music, do you?\n",
      "It goes like this\n",
      "The fourth, the fifth\n",
      "The minor fall, the major lift\n",
      "The baffled king composing Hallelujah Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah\n",
      "Hallelujah Your faith was strong but you needed proof\n",
      "You saw her bathing on the roof\n"
     ]
    }
   ],
   "source": [
    "for idx, sentence in enumerate(raw_corpus):\n",
    "    if len(sentence) == 0: continue   #길이가 0인 문장은 건너뜁니다.\n",
    "    if sentence[0] == '[': continue    # 문장 처음이 '['인 문장은 건너뜁니다.\n",
    "    if sentence[-1] == ']': continue   # 문장 끝이 ']'d인 문장은 건너뜁니다.\n",
    "    if idx > 10: break   #문장 10개만 확인\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd8807",
   "metadata": {},
   "source": [
    "토큰화\n",
    "\n",
    "    1. 문장 부호 양쪽에 공백을 추가\n",
    "    2. 모든 문자들을 소문자로 변환\n",
    "    3. 특수문자들은 모두 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77cb92e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()    # 소문자로 바꾸고 양족 공백을 삭제\n",
    "    \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)     # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)             # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)   # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "    \n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    sentence = '<start> ' + sentence + ' <end>'       # 문자 앞뒤로 <start>와 <end> 를 단어처럼 붙여줌\n",
    "    \n",
    "    if \"verse\" in sentence:\n",
    "        sentence = sentence.replace(\"verse\", \"\")\n",
    "    if \"chorus\" in sentence:\n",
    "        sentence = sentence.replace(\"chorus\", \"\")\n",
    "        \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82dc7261",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "    a0 = preprocess_sentence(sentence)\n",
    "    if len(a0.split()) > 15: continue\n",
    "    corpus.append(a0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "311b9622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156262\n",
      "[[   2   50    4 ...    0    0    0]\n",
      " [   2   15 2971 ...    0    0    0]\n",
      " [   2   33    7 ...   46    3    0]\n",
      " ...\n",
      " [   2    4  117 ...    0    0    0]\n",
      " [   2  257  195 ...   12    3    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7faae6447e80>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=7000,  # 전체 단어의 개수 \n",
    "        filters=' ',    # 별도로 전처리 로직을 추가할 수 있음. 이번에는 사용하지 안함\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 <unk> 처리\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 구축한 corpus로부터 Tokenizer가 사전을 자동구축\n",
    "\n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환.\n",
    "   \n",
    "    for num in tensor:\n",
    "        if len(num) >= 29:\n",
    "            tensor = np.delete(tensor, num)\n",
    "            \n",
    "    print(len(tensor))\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post',maxlen=15)  \n",
    "\n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "    \n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff3d949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "# 단어 사전 어떻게 생겼는지 확인\n",
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b8d0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성, 마지막 토근은 <end> 가 아니라 <pad> 일 가능성이 높다.\n",
    "tgt_input = tensor[:, 1:]   # tensor에서 <start>를 잘라내서 타켓 문장을 생성.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cda4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                                         tgt_input,\n",
    "                                                         test_size=0.2, \n",
    "                                                         shuffle=True,\n",
    "                                                         random_state=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f361c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (125009, 14)\n",
      "Target Train: (125009, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fc9c04",
   "metadata": {},
   "source": [
    "-> 학습데이터 갯수가 124960개 이하이므로 이대로 학습을 시켜주겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5f7ed1",
   "metadata": {},
   "source": [
    "## 평가 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065264e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_spoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 15000개와, 여기 포함되지 않은 0:<pad>를 포함하여 15001개\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((src_input, tgt_input)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e766e5",
   "metadata": {},
   "source": [
    "## 인공지능 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81b7ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize = (12, 8))\n",
    "    \n",
    "    for i in range(len(ax)):\n",
    "        ax[i].set_xlabel('Epochs')\n",
    "        ax[i].set_ylabel('Value')\n",
    "        \n",
    "        for n in range(len(list_of_metrics)):\n",
    "            if i == 0:\n",
    "                y = hist[list_of_metrics[n]]\n",
    "                if n == 0:\n",
    "                    ax[i].plot(epochs, y, label=\"train\")\n",
    "                else:\n",
    "                    ax[i].plot(epochs, y, label=\"val\")\n",
    "                ax[i].set_title('Loss')\n",
    "                ax[i].legend(loc='upper right')\n",
    "                if n == 1:\n",
    "                    break\n",
    "            else:\n",
    "                if n >= 2:\n",
    "                    y = hist[list_of_metrics[n]]\n",
    "                    if n == 2:\n",
    "                        ax[i].plot(epochs, y, label=\"train\")\n",
    "                    else:\n",
    "                        ax[i].plot(epochs, y, label=\"val\")\n",
    "                    ax[i].set_title('Accuracy')\n",
    "                    ax[i].legend(loc='lower right')\n",
    "                    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3114b178",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.drop  = tf.keras.layers.Dropout(0.5)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.drop(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 2048\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca8a8a9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 7001), dtype=float32, numpy=\n",
       "array([[[-1.79298848e-04, -2.06168101e-04, -6.66256310e-05, ...,\n",
       "          2.40608460e-05,  7.80462942e-05, -7.47865051e-05],\n",
       "        [-2.38764682e-04, -5.85020229e-04, -2.65241542e-04, ...,\n",
       "          2.01656323e-04,  1.17529642e-04,  5.28888777e-05],\n",
       "        [-5.37206419e-04, -8.79778643e-04, -1.32479880e-04, ...,\n",
       "         -5.25574505e-05,  7.69210747e-05, -1.69700309e-06],\n",
       "        ...,\n",
       "        [-9.77793126e-04, -3.09300842e-03,  3.24535824e-04, ...,\n",
       "         -2.15757615e-03,  7.98548921e-04, -6.60122430e-04],\n",
       "        [-6.16260688e-04, -2.95941532e-03, -7.19935488e-05, ...,\n",
       "         -2.28729961e-03,  8.30297824e-04, -6.28554320e-04],\n",
       "        [-2.82949739e-04, -2.82829045e-03, -4.29448613e-04, ...,\n",
       "         -2.36361101e-03,  8.69394047e-04, -5.93648234e-04]],\n",
       "\n",
       "       [[-1.79298848e-04, -2.06168101e-04, -6.66256310e-05, ...,\n",
       "          2.40608460e-05,  7.80462942e-05, -7.47865051e-05],\n",
       "        [-1.21241414e-04, -3.14483070e-04, -4.53337088e-05, ...,\n",
       "         -4.20543802e-05, -9.74655268e-05, -2.20295678e-05],\n",
       "        [ 2.33895102e-04, -5.28845820e-04,  1.65823469e-04, ...,\n",
       "         -1.91946761e-04, -1.72947330e-04, -1.08238215e-04],\n",
       "        ...,\n",
       "        [ 1.64234790e-03, -4.26751474e-04, -1.35244278e-03, ...,\n",
       "         -9.63703031e-04,  1.79771427e-03, -2.04816257e-04],\n",
       "        [ 1.62667839e-03, -6.47704233e-04, -1.41582196e-03, ...,\n",
       "         -1.02826359e-03,  1.93238549e-03, -2.41558722e-04],\n",
       "        [ 1.62962300e-03, -8.69157026e-04, -1.43960305e-03, ...,\n",
       "         -1.07006927e-03,  2.04311265e-03, -2.77919054e-04]],\n",
       "\n",
       "       [[-1.79298848e-04, -2.06168101e-04, -6.66256310e-05, ...,\n",
       "          2.40608460e-05,  7.80462942e-05, -7.47865051e-05],\n",
       "        [-2.22880801e-04, -2.56306055e-04,  6.69200526e-05, ...,\n",
       "         -1.57712038e-05, -1.76072226e-05, -1.76518748e-04],\n",
       "        [-8.20001587e-05, -3.50691873e-04, -1.66813377e-04, ...,\n",
       "          1.96960696e-04,  2.71530385e-04, -2.65685143e-04],\n",
       "        ...,\n",
       "        [ 2.51902529e-04,  4.10720648e-04,  1.88121933e-03, ...,\n",
       "          1.65471237e-03, -9.18719859e-04,  1.17870385e-03],\n",
       "        [ 2.10817307e-04,  4.80138369e-05,  2.00806581e-03, ...,\n",
       "          1.36512914e-03, -9.90171335e-04,  1.37756916e-03],\n",
       "        [ 3.84973915e-04, -3.14604375e-04,  2.02643056e-03, ...,\n",
       "          1.10212434e-03, -8.30343226e-04,  1.14442909e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.79298848e-04, -2.06168101e-04, -6.66256310e-05, ...,\n",
       "          2.40608460e-05,  7.80462942e-05, -7.47865051e-05],\n",
       "        [-3.04991816e-04, -2.64847564e-04, -1.33715994e-05, ...,\n",
       "          1.86801350e-04,  2.70439341e-04, -3.11988297e-05],\n",
       "        [-4.72346786e-04, -8.40185094e-05, -7.62019190e-05, ...,\n",
       "          8.44729220e-05,  6.17251324e-04,  4.54442925e-04],\n",
       "        ...,\n",
       "        [ 1.11337157e-03, -8.95166886e-04, -5.29101701e-04, ...,\n",
       "         -1.28349976e-03,  1.29697530e-03, -4.01787402e-04],\n",
       "        [ 1.18021551e-03, -9.10335861e-04, -7.57649192e-04, ...,\n",
       "         -1.32502627e-03,  1.50105660e-03, -4.72898741e-04],\n",
       "        [ 1.23573153e-03, -9.61782993e-04, -9.31632472e-04, ...,\n",
       "         -1.35005137e-03,  1.68695685e-03, -5.26799180e-04]],\n",
       "\n",
       "       [[-1.79298848e-04, -2.06168101e-04, -6.66256310e-05, ...,\n",
       "          2.40608460e-05,  7.80462942e-05, -7.47865051e-05],\n",
       "        [-2.38764682e-04, -5.85020229e-04, -2.65241542e-04, ...,\n",
       "          2.01656323e-04,  1.17529642e-04,  5.28888777e-05],\n",
       "        [ 1.11304144e-05, -8.34996637e-04, -3.82445229e-04, ...,\n",
       "          1.75832145e-04,  8.72113305e-05,  2.70736375e-04],\n",
       "        ...,\n",
       "        [ 1.80049357e-03, -3.07347946e-04,  1.79330772e-03, ...,\n",
       "         -3.53698924e-05,  1.21798227e-03,  8.02963157e-04],\n",
       "        [ 1.65583228e-03, -4.41757089e-04,  1.35586399e-03, ...,\n",
       "         -1.62831828e-04,  1.36384368e-03,  7.61034782e-04],\n",
       "        [ 1.51302421e-03, -5.92121796e-04,  8.94693134e-04, ...,\n",
       "         -3.29504313e-04,  1.49365072e-03,  7.07106956e-04]],\n",
       "\n",
       "       [[-1.79298848e-04, -2.06168101e-04, -6.66256310e-05, ...,\n",
       "          2.40608460e-05,  7.80462942e-05, -7.47865051e-05],\n",
       "        [-3.40611499e-04, -6.76833035e-04, -1.74954228e-04, ...,\n",
       "          2.32697435e-04,  1.13127775e-04, -1.27472653e-04],\n",
       "        [-3.11344193e-04, -7.48099701e-04, -3.02036729e-04, ...,\n",
       "          3.20872168e-05,  2.88222305e-04, -3.84588348e-04],\n",
       "        ...,\n",
       "        [ 2.70183838e-04, -1.21387932e-03,  6.80773519e-05, ...,\n",
       "         -9.22464358e-04,  2.97803897e-04,  6.11916112e-05],\n",
       "        [ 4.05575061e-04, -1.25122059e-03, -3.47726571e-04, ...,\n",
       "         -1.01407105e-03,  5.07378078e-04, -3.16231817e-05],\n",
       "        [ 5.02512441e-04, -1.29394210e-03, -7.44558463e-04, ...,\n",
       "         -1.10742322e-03,  7.26401282e-04, -7.61767515e-05]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24159de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  1792256   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  18882560  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  14345049  \n",
      "=================================================================\n",
      "Total params: 68,582,489\n",
      "Trainable params: 68,582,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c35927d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "610/610 [==============================] - 250s 406ms/step - loss: 3.1866\n",
      "Epoch 2/5\n",
      "610/610 [==============================] - 248s 406ms/step - loss: 2.7339\n",
      "Epoch 3/5\n",
      "610/610 [==============================] - 248s 407ms/step - loss: 2.5062\n",
      "Epoch 4/5\n",
      "610/610 [==============================] - 248s 406ms/step - loss: 2.3040\n",
      "Epoch 5/5\n",
      "610/610 [==============================] - 248s 406ms/step - loss: 2.1147\n",
      "489/489 [==============================] - 220s 447ms/step - loss: 1.9412 - val_loss: 1.8095\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "model.fit(dataset, epochs=5)\n",
    "\n",
    "history = model.fit(enc_train, \n",
    "          dec_train,\n",
    "          batch_size=256,\n",
    "          validation_data=(enc_val, dec_val),\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99fb5db2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977/977 - 33s - loss: 1.8095\n",
      "1.8094978332519531\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(enc_val,  dec_val, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12a9b14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_curve(epochs, hist, list_of_metrics):\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize = (12, 8))\n",
    "    \n",
    "    for i in range(len(ax)):\n",
    "        ax[i].set_xlabel('Epochs')\n",
    "        ax[i].set_ylabel('Value')\n",
    "        \n",
    "        for n in range(len(list_of_metrics)):\n",
    "            if i == 0:\n",
    "                y = hist[list_of_metrics[n]]\n",
    "                if n == 0:\n",
    "                    ax[i].plot(epochs, y, label=\"train\")\n",
    "                else:\n",
    "                    ax[i].plot(epochs, y, label=\"val\")\n",
    "                ax[i].set_title('Loss')\n",
    "                ax[i].legend(loc='upper right')\n",
    "                if n == 1:\n",
    "                    break\n",
    "            else:\n",
    "                if n >= 2:\n",
    "                    y = hist[list_of_metrics[n]]\n",
    "                    if n == 2:\n",
    "                        ax[i].plot(epochs, y, label=\"train\")\n",
    "                    else:\n",
    "                        ax[i].plot(epochs, y, label=\"val\")\n",
    "                    ax[i].set_title('Accuracy')\n",
    "                    ax[i].legend(loc='lower right')\n",
    "                    \n",
    "    plt.show()\n",
    "plot_curve(history.epoch, history.history, ['loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "193cc703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <END>를 예측하지 않았거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4ec9acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , i love you <end> '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16cf4c62",
   "metadata": {},
   "source": [
    "### 회고\n",
    "\n",
    "유난히 많은 시간이 걸렸던 노드였던것같다.\n",
    "자연어 처리를 노래 가사로 실험해볼 수 있던게 흥미로웠다.\n",
    "인공지능은 결국 사람을 모방한 것이므로 사람이 언어를 인식하는 방식과 유사해질수록 인공지능의 성능이 높아지지 않을까 하는 생각을 했다.\n",
    "loss 값을 2.2 이하로 떨어뜨리기 위해 epoch, embedding_size, hidden_size 값을 수정했다.\n",
    "epoch를 제외하고 주로 증가를 하는 방향으로 갔던 것 같다. \n",
    "처음엔 epoch 값을 10, 30으로도 해보았지만 시간이 너무 오래 걸려 최소한의 epoch로 loss 값을 2.2 이하로 맞추는 값을 찾기 위해 수정을 가했다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac1e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
